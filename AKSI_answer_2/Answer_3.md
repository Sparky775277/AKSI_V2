### Вопрос 03

## Простейшие методы построения префиксных кодов: метод Фано, метод Шеннона, метод Хаффмана.

​			Метод Фано (из Чечеты)

​		Всюду предполагаем, что на алфавите источника сообщения $A = \{a_1,\ldots,a_m\}, (m\ge2)$ задано распределение вероятностей $\vec{p} = (p_1,\ldots,p_m)$, причем вероятности символов упорядочены в невозрастающем порядке, т.е $p_1\ge p_2 \ge \ldots \ge p_m$.

​		Выберем число $k,1\le k \le m$, так, чтобы величина  
$$
|\sum_{i=1}^kp_i-\sum_{i=k+1}^mp_i|
$$
  была минимальной. Разобьем множество $A = \{ a_1,\ldots,a_m\}$ на подмножества: $A = A_0 \cup A_1$, где $A_0 = \{ a_1,\ldots,a_k\}, A_1 = \{ a_{k+1},\ldots,a_m\}$.

​		Следующие шаги алгоритма определим индуктивно. Предположим, что что уже задано подмножество $A_{i_1},\ldots, A_{i_t} \subseteq A$, где $i_1\ldots \in B$.

​		Если подмножество $A_{i_1},\ldots, A_{i_t}$ состоит из единственного символа $a_j$, то для этого символа определяем кодирование $\upvarphi(a_j) = i_1,\ldots,i_t$. Если в подмножестве $A_{i_1},\ldots, A_{i_t} = \{a_j,\ldots,a_s\}$ не менее двух символов, то выберем число $k,k \le k <s$,так, чтобы минимизировать величину разницы (формула выше), и разобьем множество $A_{i_1},\ldots, A_{i_t}$ на два подмножества.

​		Процесс разбиения продолжается на подмножества продолжается, пока не получим все одноэлементные подмножества и тем самым не определим кодирование $\upvarphi$ всюду на алфавите $A$.

​		Метод Фано (от мси Хренова)

​		Множество разбивается на D множеств так, чтобы суммарная вероятность множеств была минимальная. Затем каждое такое подмножество разбивается по такому же принципу. Когда множество нельзя будет разбить - алгоритм выполнен. При разбиении каждому подмножеству присваивается буква из исходного алфавита (0,1,...). Таким образом, кодировка символа будет лежать на пути от корня до этого самого листка-символа. <u>Замечание</u>: может получиться, что минимальная разница одинаковая в двух случаях - тут по договорённости по типу: докидывать лишний элемент в первое или второе множество. <u>Кодирование является не всегда оптимальным!</u>

​		Алгоритм Хаффмана (от Чечеты)

​		1-ый этап - построение двоичного дерева. Будем строить двоичное дерево с $m$ листьями, начиная с листьев и продвигаясь к корню. Возьмём в качестве листьев дерева символы $a_1,\ldots,a_m$, которым приписаны вероятности $p_1,\ldots,p_m$.

​		Основная операция алгоритма - редукция - состоит в следующем: возьмем две вершины $a_{m-1}$ и $a_m$ с <u>наименьшими</u> вероятностями $p_{m-1}$ и $p_m$ и добавим в дерево новую вершину $a_{m-1} \cup a_m$, которой припишем вероятность $p_{m-1} + p_m$. Вершину $a_{m-1} \cup a_m$ соединим рёбрами с вершинами $a_{m-1}$ и $a_m$ и объявим общим предком для для этих вершин. Ребро $a_{m-1}\cup a_m$ к $a_{m-1}$ пометим символом 0, а другое ребро - символом 1. Получаем новый (редуцированный) алфавит $A^{(1)} = \{a_1,\ldots,a_{m-2}, a_{m-1}\cup a_m\}$ c набором вероятностей $\vec{p}^{(1)} = \{p_1,\ldots,p_{m-2}, p_{m-1}+ p_m\}$.

​		Если в полученном алфавите $A^{(1)}$ не менее двух символов, то упорядочим эти символы в порядке невозрастания вероятностей набора $\vec{p}^{(1)}$ и снова применим операцию редукции.

​		Если же алфавит  $A^{(1)}$ состоит из одного символа с приписанной ему вероятностью 1, то этот один символ объявим корнем и завершим этап построения дерева.

​		2-ой этап - кодирование. Чтобы получить кодовое слово $\upvarphi(a_j)$ для символа $a_j$, последовательно считываем метки рёбер на пути от корня дерева к листу $a_j$. 

​		Метод Хаффмана (от мси Хренова)

​		Выписывается набор вероятностей по убыванию с соответствующими им символами: берутся два наименьших и образуют новый узел, в котором уже будет два символа и их суммарная вероятность. От него к соответствующим буквам ставятся ребра с соответствующими 0 и 1. Заместо наименьших узлов ставится новый так, чтобы сохранилась неубываемость. Затем берутся снова наименьшие два элемента и аналогичным способом объединяются. Алгоритм продолжается до тех пор, пока в наборе не останется один узел. <u>Замечание:</u> Кодировка символов идет от корня к листу. Кодировка является оптимальной. 

<u>Если алфавит недвоичный, то есть $D>2$</u> перед началом алгоритма нужно провести склейку последних элементов, число которых равно делению с остатком $n$ на $D$. Затем алгоритм начинается, как обычный, но берется не 2 наименьших, а $D$.

​		Метод Шеннона (из лекций)

​		Рассмотрим 

1. Упорядочим буквы алфавита $A$ по убыванию вероятностей $p(a_1) \ge p(a_2) \ge \ldots \ge p(a_1) > 0$.

2. Определим набор вспомогательных натуральных чисел $l_i(\overline{1,4})$​ из условия 
   $$
   \frac1{2^{l_i}} \le p(a_i) \le \frac1{2^{l_i-1}}$​
   $$

3. Для $i=\overline{1,n}$ подсчитаем некоторые суммы: $p_1 = 0; p_i = p_{i-1} + p(a_{i-1})$;

4. Находим первые после запятой $l_i$ знаков разложения числа $p_i$ в двоичную дробь. Цифры этого разложения являются кодовым словом, соответствующим букве $a_i$.

5. Если необходимо, провести операцию усечения кодового дерева.

   <u>Замечание:</u> усечением называется процесс удаления такого ребра, у которого нет брата (другого дочернего узла корня) и двух дочерних узлов.



